{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPcgX6MIEdhddH17yvPg4Ry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zephyris/discoba_alphafold/blob/main/DiscobaAlphaFold2HMMERv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "\n",
        "from sys import version_info \n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "\n",
        "def add_hash(x,y):\n",
        "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "\n",
        "query_sequence = 'MESKPNHRRVWVTSAVVLTALVTLIVRRRQQKRQLARRTAADAMHEELAEALKQTLLPVLVRPEDLPAGWGVAPPVFYPPYCAAIPLVLPREMQESERDSSGVRSASTSRFQGGGADGLAVAPTAFLFCSYTGYTAGPFATRQDEEVFLTEVLAHHPVLRERLAENPRQWSPLPESAPHASTDAKTAAAVTEGRRQNSFPRTFSHVLVSDDCVLLAGMNGPYTVVAVLTDFAGAWPLSRTARASADGEESGRRRTGSAAPPTIAEETELSDAIEGIACATINVPLATLGSDSAALAFRVPGTCFAAHQGYYRVVCAREGRELELCVPPEWTMRSECVNTSCTTPAGPPVPARKPVSTVGEDAESKGIILTLSFTPSSFMSEGRVDVCISAELFSALYEEPQAAAATLWAASGATDVCNPVAKATLGALTARPLPASSHARTNVVTMVYVQPKFGVLFSVHPRSAVVYEPWMTEQPTILYYPLGDAADDEGSPRMTIEYVVELPKTWEVFARDDEEFVHNVLFHFTSGEAAAISTTLTEISGIRCAMFHETRESRRCRTYVLPRGATLLVIRWETLAESWDKDLPVFQQTLDTLHIDAAAVIQFWVVVTMLVIVFAMGIGVGAENPKDHNKDEHEALCSVLSLAVTLFESGQAGNKLQKALGWALFGSETGESNTASLLAAPP ' #@param {type:\"string\"}\n",
        "\n",
        "# remove whitespaces\n",
        "query_sequence = \"\".join(query_sequence.split())\n",
        "\n",
        "jobname = 'A4IBK2' #@param {type:\"string\"}\n",
        "# remove whitespaces\n",
        "basejobname = \"\".join(jobname.split())\n",
        "basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "jobname = add_hash(basejobname, query_sequence)\n",
        "os.makedirs(jobname, exist_ok=True)\n",
        "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "fasta_path = os.path.join(jobname, f\"{jobname}.fasta\")\n",
        "\n",
        "while os.path.isfile(queries_path):\n",
        "  jobname = add_hash(basejobname, ''.join(random.sample(query_sequence,len(query_sequence))))\n",
        "  os.makedirs(jobname, exist_ok=True)\n",
        "  queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "  fasta_path = os.path.join(jobname, f\"{jobname}.fasta\")\n",
        "\n",
        "with open(queries_path, \"w\") as text_file:\n",
        "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "with open(fasta_path, \"w\") as fasta_file:\n",
        "  fasta_file.write(f\">{jobname}\\n{query_sequence}\")\n",
        "\n",
        "# number of models to use\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "#@markdown - specify how many of the top ranked structures to relax using amber\n",
        "template_mode = \"none\" #@param [\"none\", \"pdb70\",\"custom\"]\n",
        "#@markdown - `none` = no template information is used. `pdb70` = detect templates in pdb70. `custom` - upload and search own templates (PDB or mmCIF format))\n",
        "\n",
        "if template_mode == \"pdb70\":\n",
        "  use_templates = True\n",
        "  custom_template_path = None\n",
        "elif template_mode == \"custom\":\n",
        "  custom_template_path = os.path.join(jobname,f\"template\")\n",
        "  os.makedirs(custom_template_path, exist_ok=True)\n",
        "  uploaded = files.upload()\n",
        "  use_templates = True\n",
        "  for fn in uploaded.keys():\n",
        "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "else:\n",
        "  custom_template_path = None\n",
        "  use_templates = False\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DkHAO9F8mopr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qc3nd3HymIE_"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "# Install ColabFold and dependencies\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  echo \"installing colabfold...\"\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\n",
        "  # high risk high gain\n",
        "  pip install -q \"jax[cuda11_cudnn805]>=0.3.8,<0.4\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "\n",
        "  # for debugging\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    echo \"installing conda...\"\n",
        "    wget -qnc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    bash Miniconda3-latest-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniconda3-latest-Linux-x86_64.sh\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  echo \"installing hhsuite...\"\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  echo \"installing amber...\"\n",
        "  conda install -y -q -c conda-forge openmm=7.5.1 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi\n",
        "\n",
        "#Install Hmmer, for search and alignment\n",
        "if [ ! -f HMMER_READY ]; then\n",
        "  apt-get install hmmer > /dev/null 2>&1\n",
        "  touch HMMER_READY\n",
        "fi\n",
        "\n",
        "#Download the custom Discoba database\n",
        "if [ ! -f DISCOBA_READY ]; then\n",
        "  if [ -d discoba ]; then\n",
        "    rm -r discoba\n",
        "  fi\n",
        "  mkdir discoba\n",
        "  cd discoba\n",
        "    curl https://zenodo.org/record/5682928/files/discobaStats.txt?download=1\n",
        "    curl https://zenodo.org/record/5682928/files/discoba.fasta.gz?download=1 -s -L -o discoba.fasta.gz\n",
        "    gzip -d discoba.fasta.gz\n",
        "  cd ..\n",
        "  touch DISCOBA_READY\n",
        "fi\n",
        "\n",
        "#Install hh-suite\n",
        "if [ ! -f HHSUITE_READY ]; then\n",
        "  if [ -d hh-suite ]; then\n",
        "    rm -r hh-suite\n",
        "  fi\n",
        "  git clone https://github.com/soedinglab/hh-suite\n",
        "  touch HHSUITE_READY\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Generate custom multiple sequence alignment\n",
        "\n",
        "msa_use_discoba = True #@param {type:\"boolean\"}\n",
        "msa_use_colabfold = True #@param {type:\"boolean\"}\n",
        "msa_colabfold_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\"]\n",
        "\n",
        "# discoba MSA\n",
        "# system call to hmmer\n",
        "import os\n",
        "\n",
        "if not os.path.isfile(os.path.join(jobname, f\"{jobname}.hmm.a3m\")) and msa_use_discoba:\n",
        "  print(\"Doing HMMER search against Discoba\")\n",
        "  os.system(\"jackhmmer -A \"+os.path.join(jobname, f\"{jobname}.hmm.sto\")+\" -o \"+os.path.join(jobname, f\"{jobname}.hmm.out\")+\" \"+os.path.join(jobname, f\"{jobname}.fasta\")+\" \"+os.path.join(\"discoba\", \"discoba.fasta\"))\n",
        "  os.system(\"perl hh-suite/scripts/reformat.pl sto a3m \"+os.path.join(jobname, f\"{jobname}.hmm.sto\")+\" \"+os.path.join(jobname, f\"{jobname}.hmm.a3m\"))\n",
        "\n",
        "# mmseqs2 msa\n",
        "# dummy colabfold prediction\n",
        "if not os.path.isfile(os.path.join(jobname, f\"{jobname}.mms.a3m\")) and msa_use_colabfold:\n",
        "  print(\"Fetching MMSeqs2 search\")\n",
        "  msa_mode = msa_colabfold_mode\n",
        "  pair_mode = \"unpaired_paired\"\n",
        "\n",
        "  import sys\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "  from Bio import BiopythonDeprecationWarning\n",
        "  warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "  from pathlib import Path\n",
        "  from colabfold.download import download_alphafold_params, default_data_dir\n",
        "  from colabfold.utils import setup_logging\n",
        "  from colabfold.batch import get_queries, run, set_model_type\n",
        "  from colabfold.plot import plot_msa_v2\n",
        "\n",
        "  import os\n",
        "  import numpy as np\n",
        "\n",
        "  from colabfold.colabfold import plot_protein\n",
        "  from pathlib import Path\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  def input_features_callback(input_features):\n",
        "    do_nothing = \"at all\"\n",
        "    #print(\"Input processed...\")\n",
        "\n",
        "  def prediction_callback(protein_obj, length, prediction_result, input_features, mode):\n",
        "    do_nothing = \"even now\"\n",
        "    #print(\"Should never be called...\")\n",
        "\n",
        "  if 'logging_setup' not in globals():\n",
        "    setup_logging(Path(os.path.join(jobname,\"log.txt\")))\n",
        "    logging_setup = True\n",
        "\n",
        "  queries, is_complex = get_queries(queries_path)\n",
        "  model_type = set_model_type(is_complex, \"alphafold2_ptm\")\n",
        "\n",
        "  download_alphafold_params(model_type, Path(\".\"))\n",
        "  try:\n",
        "    results = run(\n",
        "      queries=queries,\n",
        "      result_dir=jobname,\n",
        "      use_templates=use_templates,\n",
        "      custom_template_path=custom_template_path,\n",
        "      num_relax=num_relax,\n",
        "      msa_mode=msa_mode,    \n",
        "      model_type=model_type,\n",
        "      num_models=0, # set to zero, results in a3m but prediction failure\n",
        "      num_recycles=None,\n",
        "      recycle_early_stop_tolerance=None,\n",
        "      num_seeds=1,\n",
        "      use_dropout=None,\n",
        "      model_order=[1,2,3,4,5],\n",
        "      is_complex=is_complex,\n",
        "      data_dir=Path(\".\"),\n",
        "      keep_existing_results=False,\n",
        "      rank_by=\"auto\",\n",
        "      pair_mode=pair_mode,\n",
        "      stop_at_score=float(100),\n",
        "      prediction_callback=prediction_callback,\n",
        "      dpi=200,\n",
        "      zip_results=False,\n",
        "      save_all=False,\n",
        "      max_msa=None,\n",
        "      use_cluster_profile=True,\n",
        "      input_features_callback=input_features_callback,\n",
        "      save_recycles=False,\n",
        "    )\n",
        "  except:\n",
        "    print(\"Colabfold exception\")\n",
        "    print(\"Expected exception: a3m should have been fetched\")\n",
        "    # write all but first line of a3m as a3m result\n",
        "    f = open(os.path.join(jobname, f\"{jobname}.a3m\"), \"r\")\n",
        "    lines = f.read().splitlines()[1:]\n",
        "    f.close()\n",
        "    f = open(os.path.join(jobname, f\"{jobname}.tmp.a3m\"), \"w\")\n",
        "    for line in lines:\n",
        "      f.write(line + \"\\n\")\n",
        "    f.close()\n",
        "    os.system(\"perl hh-suite/scripts/reformat.pl a3m a3m \"+os.path.join(jobname, f\"{jobname}.tmp.a3m\")+\" \"+os.path.join(jobname, f\"{jobname}.mms.a3m\"))\n",
        "\n",
        "# join outputs\n",
        "f = open(os.path.join(jobname, f\"{jobname}.custom.a3m\"), \"w\")\n",
        "if msa_use_discoba:\n",
        "  i = open(os.path.join(jobname, f\"{jobname}.mms.a3m\"), \"r\")\n",
        "  f.write(i.read()+\"\\n\")\n",
        "  i.close()\n",
        "if msa_use_colabfold:\n",
        "  i = open(os.path.join(jobname, f\"{jobname}.hmm.a3m\"), \"r\")\n",
        "  f.write(i.read()+\"\\n\")\n",
        "  i.close()\n",
        "f.close()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1hyCvtFPc-Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Advanced settings\n",
        "model_type = \"alphafold2_ptm\"\n",
        "num_recycles = \"auto\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
        "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
        "#@markdown - if `auto` selected, will use 20 recycles if `model_type=alphafold2_multimer_v3` (with tol=0.5), all else 3 recycles (with tol=0.0).\n",
        "\n",
        "#@markdown #### Sample settings\n",
        "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
        "#@markdown -  decrease `max_msa` to increase uncertainity\n",
        "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
        "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "\n",
        "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "if max_msa == \"auto\": max_msa = None\n",
        "\n",
        "#@markdown #### Save settings\n",
        "save_all = False #@param {type:\"boolean\"}\n",
        "save_recycles = False #@param {type:\"boolean\"}\n",
        "save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
        "dpi = 200 #@param {type:\"integer\"}\n",
        "#@markdown - set dpi for image resolution\n",
        "\n",
        "if save_to_google_drive:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form."
      ],
      "metadata": {
        "cellView": "form",
        "id": "f104f1cSNBRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real prediction, using custom a3m\n",
        "msa_mode = \"custom\"\n",
        "pair_mode = \"unpaired\"\n",
        "a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "queries_path=a3m_file\n",
        "\n",
        "#@title Run Prediction\n",
        "display_images = True #@param {type:\"boolean\"}\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from Bio import BiopythonDeprecationWarning\n",
        "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "from pathlib import Path\n",
        "from colabfold.download import download_alphafold_params, default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from colabfold.batch import get_queries, run, set_model_type\n",
        "from colabfold.plot import plot_msa_v2\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "try:\n",
        "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "except:\n",
        "  K80_chk = \"0\"\n",
        "  pass\n",
        "if \"1\" in K80_chk:\n",
        "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "from colabfold.colabfold import plot_protein\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "def input_features_callback(input_features):  \n",
        "  if display_images:    \n",
        "    plot_msa_v2(input_features)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def prediction_callback(protein_obj, length,\n",
        "                        prediction_result, input_features, mode):\n",
        "  model_name, relaxed = mode\n",
        "  if not relaxed:\n",
        "    if display_images:\n",
        "      fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "result_dir = jobname\n",
        "if 'logging_setup' not in globals():\n",
        "    setup_logging(Path(os.path.join(jobname,\"log.txt\")))\n",
        "    logging_setup = True\n",
        "\n",
        "queries, is_complex = get_queries(queries_path)\n",
        "model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "if \"multimer\" in model_type and max_msa is not None:\n",
        "  use_cluster_profile = False\n",
        "else:\n",
        "  use_cluster_profile = True\n",
        "\n",
        "download_alphafold_params(model_type, Path(\".\"))\n",
        "results = run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    custom_template_path=custom_template_path,\n",
        "    num_relax=num_relax,\n",
        "    msa_mode=msa_mode,    \n",
        "    model_type=model_type,\n",
        "    num_models=5,\n",
        "    num_recycles=num_recycles,\n",
        "    recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "    num_seeds=num_seeds,\n",
        "    use_dropout=use_dropout,\n",
        "    model_order=[1,2,3,4,5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=Path(\".\"),\n",
        "    keep_existing_results=False,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=pair_mode,\n",
        "    stop_at_score=float(100),\n",
        "    prediction_callback=prediction_callback,\n",
        "    dpi=dpi,\n",
        "    zip_results=False,\n",
        "    save_all=save_all,\n",
        "    max_msa=max_msa,\n",
        "    use_cluster_profile=use_cluster_profile,\n",
        "    input_features_callback=input_features_callback,\n",
        "    save_recycles=save_recycles,\n",
        ")\n",
        "results_zip = f\"{jobname}.result.zip\"\n",
        "os.system(f\"zip -r {results_zip} {jobname}\")"
      ],
      "metadata": {
        "id": "nX5VDpvfL4IQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "import py3Dmol\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from colabfold.colabfold import plot_plddt_legend\n",
        "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
        "rank_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
        "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "\n",
        "tag = results[\"rank\"][0][rank_num - 1]\n",
        "jobname_prefix = \".custom\" if msa_mode == \"custom\" else \"\"\n",
        "pdb_filename = f\"{jobname}/{jobname}{jobname_prefix}_unrelaxed_{tag}.pdb\"\n",
        "pdb_file = glob.glob(pdb_filename)\n",
        "\n",
        "def show_pdb(rank_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
        "  model_name = f\"rank_{rank_num}\"\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
        "  view.addModel(open(pdb_file[0],'r').read(),'pdb')\n",
        "\n",
        "  if color == \"lDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "\n",
        "  view.zoomTo()\n",
        "  return view\n",
        "\n",
        "show_pdb(rank_num, show_sidechains, show_mainchains, color).show()\n",
        "if color == \"lDDT\":\n",
        "  plot_plddt_legend().show() "
      ],
      "metadata": {
        "cellView": "form",
        "id": "yHGslL-hQMmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plots {run: \"auto\"}\n",
        "from IPython.display import display, HTML\n",
        "import base64\n",
        "from html import escape\n",
        "\n",
        "# see: https://stackoverflow.com/a/53688522\n",
        "def image_to_data_url(filename):\n",
        "  ext = filename.split('.')[-1]\n",
        "  prefix = f'data:image/{ext};base64,'\n",
        "  with open(filename, 'rb') as f:\n",
        "    img = f.read()\n",
        "  return prefix + base64.b64encode(img).decode('utf-8')\n",
        "\n",
        "pae = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_pae.png\"))\n",
        "cov = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_coverage.png\"))\n",
        "plddt = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_plddt.png\"))\n",
        "display(HTML(f\"\"\"\n",
        "<style>\n",
        "  img {{\n",
        "    float:left;\n",
        "  }}\n",
        "  .full {{\n",
        "    max-width:100%;\n",
        "  }}\n",
        "  .half {{\n",
        "    max-width:50%;\n",
        "  }}\n",
        "  @media (max-width:640px) {{\n",
        "    .half {{\n",
        "      max-width:100%;\n",
        "    }}\n",
        "  }}\n",
        "</style>\n",
        "<div style=\"max-width:90%; padding:2em;\">\n",
        "  <h1>Plots for {escape(jobname)}</h1>\n",
        "  <img src=\"{pae}\" class=\"full\" />\n",
        "  <img src=\"{cov}\" class=\"half\" />\n",
        "  <img src=\"{plddt}\" class=\"half\" />\n",
        "</div>\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "toiTKfHxQPqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\").\n",
        "\n",
        "if msa_mode == \"custom\":\n",
        "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
        "\n",
        "files.download(f\"{jobname}.result.zip\")\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
        "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-PNURabClH1e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}